{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4df4ff72",
      "metadata": {},
      "source": [
        "# Tensor Train-Singular Value Decomposition (TT-SVD)\n",
        "\n",
        "In this notebook, we will walk through the process of compressing a high-dimensional tensor into a Tensor Train (TT) format using the TT-SVD algorithm.\n",
        "\n",
        "## Table of Contents:\n",
        "1. What is a Tensor Train (TT)?\n",
        "2. The TT-SVD Algorithm\n",
        "3. Reversing the decomposition: Restoring the original tensor\n",
        "4. Examples\n",
        "5. Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4aae8a9",
      "metadata": {},
      "source": [
        "## 1. What is a Tensor Train (TT)?\n",
        "A **Tensor Train** (TT), also known as a Matrix Product State (MPS), is a method to decompose a high-dimensional tensor into a series of smaller tensors. \n",
        "This decomposition makes it easier to store, manipulate, and perform computations on high-dimensional tensors.\n",
        "\n",
        "The goal of TT-SVD is to approximate a high-dimensional tensor as a series of lower-order tensors, reducing the computational and memory requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a7cac8",
      "metadata": {},
      "source": [
        "## 2. The TT-SVD Algorithm\n",
        "The TT-SVD algorithm works by performing the following steps for each mode (dimension) of the tensor:\n",
        "\n",
        "1. Reshape the tensor to a 2D matrix\n",
        "2. Perform Singular Value Decomposition (SVD)\n",
        "3. Truncate the small singular values (based on a truncation error tolerance, `eps`)\n",
        "4. Store the left singular vectors as one of the TT-cores (the decomposed tensors)\n",
        "5. Contract the singular values with the right singular vectors\n",
        "6. Repeat the process for the next mode."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46ba122d",
      "metadata": {},
      "source": [
        "Let's first import the necessary libraries and define the TT-SVD function. This function will compress a tensor into a TT format and return the truncation error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "id": "e9cbf23e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from copy import copy\n",
        "\n",
        "def tt_svd(tens: np.ndarray, eps: float = 1e-6, max_bond_dimension: int = 10**12) -> list:\n",
        "    \"\"\"\n",
        "    Compress a tensor to a MPS/TT using the TT-SVD algorithm.\n",
        "    \n",
        "    Args:\n",
        "        tens: The input tensor\n",
        "        eps: Truncation error for each SVD\n",
        "        max_bond_dimension: Maximum allowable rank for truncation\n",
        "    \n",
        "    Returns:\n",
        "        An MPS/TT as a list of order-3 tensors (dummy bonds are added to boundary tensors)\n",
        "        The total truncation error\n",
        "    \"\"\"\n",
        "    dims = tens.shape\n",
        "    N = len(dims)\n",
        "    tmp = copy(tens)\n",
        "    A = []\n",
        "    r_prev = 1\n",
        "    \n",
        "    total_trunc_error_squared = 0\n",
        "\n",
        "    for i in range(N-1):\n",
        "        # Step 1: Reshape the tensor into a 2D matrix\n",
        "        tmp = tmp.reshape(r_prev * dims[i], -1)\n",
        "        \n",
        "        # Step 2: Perform SVD\n",
        "        U, s, Vt = np.linalg.svd(tmp, full_matrices=False)\n",
        "        \n",
        "        # Step 3: Truncate small singular values (based on eps)\n",
        "        truncation_error_squared = np.cumsum(s[::-1]**2)\n",
        "        where_error_is_lower_than_eps = np.where(truncation_error_squared <= eps**2)[0]\n",
        "        \n",
        "        num_sv_to_discard = 0 if len(where_error_is_lower_than_eps) == 0 else int(1 + where_error_is_lower_than_eps[-1])\n",
        "        \n",
        "        # Compute new rank: should not be lower than 1 or greater than `max_bond_dimension`\n",
        "        r = min(max_bond_dimension, max(1, len(s) - num_sv_to_discard))\n",
        "\n",
        "        # Compute truncation error from discarded singular values\n",
        "        total_trunc_error_squared += sum(s[r:]**2)\n",
        "\n",
        "        # Step 4: Store the left singular vectors (TT-core)\n",
        "        A.append(U[:, :r].reshape(r_prev, dims[i], r))\n",
        "        \n",
        "        # Step 5: Contract singular values with right singular vectors\n",
        "        tmp = np.diagflat(s[:r]) @ Vt[:r, :]\n",
        "        r_prev = r\n",
        "    \n",
        "    # Final TT-core\n",
        "    A.append(tmp.reshape(r_prev, dims[-1], 1))\n",
        "    \n",
        "    return (A, np.sqrt(total_trunc_error_squared))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d7eff3",
      "metadata": {},
      "source": [
        "### Explanation of the Code:\n",
        "- **Input Tensor (`tens`)**: This is the high-dimensional tensor we aim to compress.\n",
        "- **Truncation Error (`eps`)**: This defines the tolerance for truncating small singular values, `eps` is the maximum allowable truncation error.\n",
        "- **Max bond dimension (`max_bond_dimension`)**: This sets the maximum allowable rank for truncation.\n",
        "- **`A` List**: This stores the sequence of TT-cores, which are the smaller tensors resulting from the decomposition.\n",
        "- **`total_trunc_error_squared`**: This stores the total trunction error squared, in the end we return the square root of this quantity. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1584bc",
      "metadata": {},
      "source": [
        "# 3. Reversing the decomposition: Restoring the original tensor\n",
        "\n",
        "As when we looked at the SVD we checked that multiplying the U, S, and Vt matrices together results in the original tensor, we can do the same here with the TT decomposition to restore the original tensor. Below is a code to do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "id": "2c4101b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def restore_full(mps: list) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Restore full tensor from an MPS/TT\n",
        "\n",
        "    Args:\n",
        "        mps: List of order-3 tensors representing an MPS/TT\n",
        "\n",
        "    Return:\n",
        "        The full tensor\n",
        "    \"\"\"\n",
        "    tmp = copy(mps[0])\n",
        "    dims = [site.shape[1] for site in mps]\n",
        "    for site in mps[1:]:\n",
        "        tmp = np.einsum('iuj,jvk->iuvk', tmp, site)\n",
        "        tmp = tmp.reshape(tmp.shape[0], tmp.shape[1] * tmp.shape[2], tmp.shape[3])\n",
        "    return tmp.reshape(dims)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff470cab",
      "metadata": {},
      "source": [
        "## 4. Examples\n",
        "\n",
        "Now, let's run through some example to see the algorithm in action."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be136724",
      "metadata": {},
      "source": [
        "### 1. Random tensor\n",
        "Letâ€™s create a random 4-dimensional tensor for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "id": "1091cca8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 3, 3, 3, 3, 2, 2)"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random 4D tensor with shape (2, 2, 2, 2, 2)\n",
        "tensor = np.random.rand(3, 3, 3, 3, 3, 2, 2)\n",
        "tensor.shape  # Confirm the shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c96df6",
      "metadata": {},
      "source": [
        "Next, we will apply the `tt_svd` function to compress this tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "id": "9599c9db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core 1: (1, 3, 3)\n",
            "Core 2: (3, 3, 9)\n",
            "Core 3: (9, 3, 27)\n",
            "Core 4: (27, 3, 12)\n",
            "Core 5: (12, 3, 4)\n",
            "Core 6: (4, 2, 2)\n",
            "Core 7: (2, 2, 1)\n",
            "Total trunction error:  0.0\n"
          ]
        }
      ],
      "source": [
        "# Apply the TT-SVD algorithm\n",
        "tt_cores, err = tt_svd(tensor, eps=1e-6)\n",
        "\n",
        "# Display the shapes of the TT-cores\n",
        "for i, core in enumerate(tt_cores):\n",
        "    print(f\"Core {i+1}: {core.shape}\")\n",
        "\n",
        "print(\"Total trunction error: \", err)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30c9a6f4",
      "metadata": {},
      "source": [
        "As you can see, the TT-SVD algorithm has decomposed our 4-dimensional tensor into several order 3 tensors (TT-cores).\n",
        "\n",
        "The truncation error, however is zero because no truncation has taken place.\n",
        "\n",
        "### Exercise: \n",
        "1. What do noticed about the bond dimensions when there is no truncation? \n",
        "2. How can we calculate the bond dimensions when there is no truncation?\n",
        "\n",
        "Let's try restoring the original tensor to make sure we get back what we started with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "id": "23201a09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restored tensor matches original tensor:  True\n"
          ]
        }
      ],
      "source": [
        "tensor_restored = restore_full(tt_cores)\n",
        "print(\"Restored tensor matches original tensor: \", bool(np.all(np.isclose(tensor_restored, tensor))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8262a99c",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "We can try experimenting with different tensors and values of `eps` and `rank` to see how they affect the compression and the sizes of the TT-cores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "id": "3e563011",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core 1: (1, 3, 3)\n",
            "Core 2: (3, 3, 9)\n",
            "Core 3: (9, 3, 27)\n",
            "Core 4: (27, 3, 12)\n",
            "Core 5: (12, 3, 4)\n",
            "Core 6: (4, 2, 2)\n",
            "Core 7: (2, 2, 1)\n",
            "Total trunction error:  0.0\n"
          ]
        }
      ],
      "source": [
        "tt_cores, err = tt_svd(tensor, eps=1e-1)\n",
        "\n",
        "# Display the shapes of the TT-cores\n",
        "for i, core in enumerate(tt_cores):\n",
        "    print(f\"Core {i+1}: {core.shape}\")\n",
        "\n",
        "print(\"Total trunction error: \", err)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec6eac0f",
      "metadata": {},
      "source": [
        "Increasing the `eps` to 10^-1 doesn't change the result - there is still no truncation. We can force a truncation by setting `max_bond_dimension`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "id": "f3a83bac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core 1: (1, 3, 3)\n",
            "Core 2: (3, 3, 4)\n",
            "Core 3: (4, 3, 4)\n",
            "Core 4: (4, 3, 4)\n",
            "Core 5: (4, 3, 4)\n",
            "Core 6: (4, 2, 2)\n",
            "Core 7: (2, 2, 1)\n",
            "Total trunction error:  7.906917862700159\n"
          ]
        }
      ],
      "source": [
        "tt_cores, err = tt_svd(tensor, eps=1e-1, max_bond_dimension=4)\n",
        "\n",
        "# Display the shapes of the TT-cores\n",
        "for i, core in enumerate(tt_cores):\n",
        "    print(f\"Core {i+1}: {core.shape}\")\n",
        "\n",
        "print(\"Total trunction error: \", err)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9e5910",
      "metadata": {},
      "source": [
        "Now we can see the maximum bond dimension is capped by the value we set and there is a large truncation error. \n",
        "\n",
        "As explained in the course this truncation error is an upper bound on the actual error of the TT approximation. To compute the actual error we need to recontruct the rank-4 tensor and check how it compares to the original tensor by computing the Frobenius norm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "id": "8c52da60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error computed with Frobenius norm:  7.9069178627001575\n",
            "Upper bound on error:  7.906917862700159\n",
            "Actual error is less than or equal to upper bound: True\n"
          ]
        }
      ],
      "source": [
        "tensor_restored = restore_full(tt_cores)\n",
        "actual_error = np.linalg.norm(tensor - tensor_restored)\n",
        "print(\"Error computed with Frobenius norm: \", actual_error)\n",
        "print(\"Upper bound on error: \", err)\n",
        "print(\"Actual error is less than or equal to upper bound:\", actual_error <= err + 10**-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92660728",
      "metadata": {},
      "source": [
        "So we confirm that the upper bound is correct for this case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aa71475",
      "metadata": {},
      "source": [
        "### 2. Sinusoidal function\n",
        "\n",
        "The above random tensor doesn't have a low TT-rank and is not approximated well by a MPS/TT with low rank. Below is an example of a tensor which does have a low TT-rank (rank-2): a sinusoidal signal reshaped into a tensor. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "id": "22e427e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a tensor by reshaping a vector of a cosine function:\n",
        "\n",
        "shape = (2, 2, 2, 2, 2, 2, 2, 2)\n",
        "\n",
        "w=1\n",
        "phi=0.5\n",
        "def x(t):\n",
        "    return np.cos(w*t + phi)\n",
        "\n",
        "tens = np.fromiter((x(t) for t in range(np.prod(shape))), dtype=np.float64).reshape(shape)\n",
        "mps, err = tt_svd(tens, eps=10**-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac011930",
      "metadata": {},
      "source": [
        "Let's write a function to help us quickly visualize the bond dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "id": "3fb95eee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS bond dimensions:  [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Total trunction error:  6.062073869922691e-16\n"
          ]
        }
      ],
      "source": [
        "# Get bond dimensions/tt-ranks\n",
        "def bdims(mps: list):\n",
        "    return [site.shape[0] for site in mps] + [mps[-1].shape[-1]]\n",
        "\n",
        "print(\"MPS bond dimensions: \", bdims(mps))\n",
        "print(\"Total trunction error: \", err)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5115658b",
      "metadata": {},
      "source": [
        "We can see that the largest bond dimension of the MPS for the cosine function is 2. The truncation error is close to zero."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c406f0",
      "metadata": {},
      "source": [
        "### 3. Exponential function\n",
        "\n",
        "An even lower TT-rank tensor (rank-1) is that given by reshaping the exponential function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "id": "22c00f07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a tensor by reshaping a vector of a exponential function:\n",
        "\n",
        "shape = (2, 2, 2, 2, 2, 2, 2, 2)\n",
        "\n",
        "w=1\n",
        "g=0.1\n",
        "def x(t):\n",
        "    return np.exp(-g*t)\n",
        "\n",
        "tens = np.fromiter((x(t) for t in range(np.prod(shape))), dtype=np.float64).reshape(shape)\n",
        "mps, err = tt_svd(tens, eps=10**-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "id": "bd0e4dcc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS bond dimensions:  [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Total trunction error:  6.062073869922691e-16\n"
          ]
        }
      ],
      "source": [
        "print(\"MPS bond dimensions: \", bdims(mps))\n",
        "print(\"Total trunction error: \", err)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "608a2bb7",
      "metadata": {},
      "source": [
        "## 5. Exercises\n",
        "1. Compute the number of parameters in the MPS representation of the three example tensors: randon, cosine and exponential.\n",
        "2. Compute the compression ratios, i.e. the by what factor have the original tensors been compressed?\n",
        "3. For the random tensor and cosine tensor, plot the truncation error as a function of the MPS bond dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf91b747",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
